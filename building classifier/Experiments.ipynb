{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from preprocessing import remove_punct_num\n",
    "from preprocessing import remove_stopwords\n",
    "from preprocessing import stemmer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../data/experiment1/shuffled_updated.csv')\n",
    "df = pd.read_csv('../data/no_stemming.csv')\n",
    "#df = pd.read_csv('../data/experiment1/shuffled1.csv')\n",
    "X, y = df['content'], df['multiclass']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42)\n",
    "# random_state = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: [236, 262, 269, 190, 83, 294, 246, 116]\n",
      "Testing Set: [59, 85, 61, 44, 23, 70, 53, 30]\n"
     ]
    }
   ],
   "source": [
    "training = [0,0,0,0,0,0,0,0]\n",
    "testing = [0,0,0,0,0,0,0,0]\n",
    "\n",
    "for y in y_train:\n",
    "    training[y] += 1\n",
    "    \n",
    "for y in y_test:\n",
    "    testing[y] += 1\n",
    "    \n",
    "print \"Training Set:\" , training\n",
    "print \"Testing Set:\" , testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1696, 31074)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1) # max_features=10000, binary=True, norm=None, use_idf=False\n",
    "X= vectorizer.fit_transform(X_train) \n",
    "train_data_features = X.toarray()\n",
    "\n",
    "print train_data_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1696, 22824)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1, binary=True, norm=None, use_idf=False) #max_features=30000\n",
    "X= vectorizer.fit_transform(X_train) \n",
    "train_data_features = X.toarray()\n",
    "\n",
    "print train_data_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1696, 22824)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=1, max_features=30000) #, binary=True, norm=None, use_idf=False\n",
    "X= vectorizer.fit_transform(X_train) \n",
    "train_data_features = X.toarray()\n",
    "\n",
    "print train_data_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = zip(vectorizer.get_feature_names(),\n",
    "                 np.asarray(X.sum(axis=0)).ravel())\n",
    "sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "# for item in sorted_scores:\n",
    "#     print \"{0:20} Score: {1}\".format(item[0], item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC(C=1.0,random_state=42)) # C=1.0, max_iter=1000\n",
    "clf.fit(train_data_features,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(train_data_features,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905882352941\n"
     ]
    }
   ],
   "source": [
    "test_data_features = vectorizer.transform(X_test)\n",
    "pred = clf.predict(test_data_features)\n",
    "accuracy = clf.score(test_data_features,y_test)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0=crime 1=disaster 2=entertainment 3=economic 4=health 5=political 6=sports 7=terrorism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print pred\n",
    "# print pred.shape\n",
    "# print y_test.values\n",
    "\n",
    "X_testArray = X_test.values\n",
    "y_testArray = y_test.values\n",
    "\n",
    "# for i in range(len(X_test)):\n",
    "#     print X_testArray[i] \n",
    "#     print \"label: \", y_testArray[i] \n",
    "#     print \"predicted: \", pred[i]\n",
    "#     print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53  2  0  0  0  2  0  2]\n",
      " [ 3 78  0  2  0  1  0  1]\n",
      " [ 0  0 61  0  0  0  0  0]\n",
      " [ 1  3  0 34  0  6  0  0]\n",
      " [ 2  2  0  0 16  2  0  1]\n",
      " [ 0  0  0  3  0 64  1  2]\n",
      " [ 0  0  0  0  0  0 53  0]\n",
      " [ 2  0  0  0  0  2  0 26]]\n"
     ]
    }
   ],
   "source": [
    "# row : actual :: column : predicted \n",
    "cf = confusion_matrix(y_testArray,pred)\n",
    "print cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime\n",
      "53 6 8 358\n",
      "Precision:  0.868852459016\n",
      "Recall:  0.898305084746\n",
      " \n",
      "Disaster\n",
      "78 7 7 333\n",
      "Precision:  0.917647058824\n",
      "Recall:  0.917647058824\n",
      " \n",
      "Entertainment\n",
      "61 0 0 364\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      " \n",
      "Economic\n",
      "34 10 5 376\n",
      "Precision:  0.871794871795\n",
      "Recall:  0.772727272727\n",
      " \n",
      "Health\n",
      "16 7 0 402\n",
      "Precision:  1.0\n",
      "Recall:  0.695652173913\n",
      " \n",
      "Political\n",
      "64 6 13 342\n",
      "Precision:  0.831168831169\n",
      "Recall:  0.914285714286\n",
      " \n",
      "Sports\n",
      "53 0 1 371\n",
      "Precision:  0.981481481481\n",
      "Recall:  1.0\n",
      " \n",
      "Terrorism\n",
      "26 4 6 389\n",
      "Precision:  0.8125\n",
      "Recall:  0.866666666667\n",
      " \n",
      "hey  385 40 40 2935 0.976470588235\n"
     ]
    }
   ],
   "source": [
    "# 8 total classes\n",
    "from __future__ import division\n",
    "\n",
    "total = 8\n",
    "classes = {0:'Crime', 1:'Disaster', 2:'Entertainment', 3:'Economic', 4:'Health', 5:'Political',\n",
    "          6:'Sports', 7:'Terrorism'}\n",
    "category = 0\n",
    "\n",
    "TrueP = []\n",
    "FalseN = []\n",
    "FalseP = []\n",
    "TrueN = []\n",
    "\n",
    "\n",
    "for category in range(total):\n",
    "    TP = FN = FP = TN = 0 \n",
    "    for i in range(total):\n",
    "        for j in range(total):\n",
    "            if i==category and j==category:\n",
    "                TP += cf[i][j]\n",
    "            elif i==category and j!=category:\n",
    "                FN += cf[i][j]\n",
    "            elif i!=category and j==category:\n",
    "                FP += cf[i][j]\n",
    "            else:\n",
    "                TN += cf[i][j]\n",
    "    print classes.get(category)\n",
    "    print TP, FN, FP, TN\n",
    "    print \"Precision: \" , TP/(TP+FP)\n",
    "    print \"Recall: \" , TP/(TP+FN)\n",
    "    print \" \"\n",
    "    TrueP.append(TP)\n",
    "    FalseN.append(FN)\n",
    "    FalseP.append(FP)\n",
    "    TrueN.append(TN)\n",
    "    \n",
    "# Average confusion matrix for all classes\n",
    "TP = np.sum(TrueP)\n",
    "FN = np.sum(FalseN)\n",
    "FP = np.sum(FalseP)\n",
    "TN = np.sum(TrueN)  \n",
    "\n",
    "print  \"hey \",  TP, FN, FP, TN, ((TP+TN)/(TP+TN+FP+FN))\n",
    "\n",
    "# PPV = TP / (TP + FP) \n",
    "# TPR = TP / (TP + FN)\n",
    "# Fscore = 2 * ((PPV * TPR)/(PPV + TPR))\n",
    "\n",
    "# print \" \"\n",
    "# print \"Precision: \" , PPV\n",
    "# print \"Recall: \" , TPR\n",
    "# print \"F-score: \" , Fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88333333  0.91764706  1.          0.81927711  0.82051282  0.8707483\n",
      "  0.99065421  0.83870968]\n",
      "\n",
      "\n",
      "0.892610312931\n"
     ]
    }
   ],
   "source": [
    "# calculate f-score for each category\n",
    "f1 = f1_score(y_testArray,pred, average=None)\n",
    "\n",
    "print f1\n",
    "print \"\\n\"\n",
    "print np.sum(f1)/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score\n",
      "-----\n",
      "Weighted:  0.905070584663\n",
      "Micro:  0.905882352941\n",
      "Macro:  0.892610312931\n"
     ]
    }
   ],
   "source": [
    "# calculate f-score for all \n",
    "print \"F-score\\n-----\"\n",
    "print \"Weighted: \", f1_score(y_testArray,pred, average='weighted')\n",
    "print \"Micro: \", f1_score(y_testArray,pred, average='micro')\n",
    "print \"Macro: \", f1_score(y_testArray,pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Crime       0.87      0.90      0.88        59\n",
      "     Disaster       0.92      0.92      0.92        85\n",
      "Entertainment       1.00      1.00      1.00        61\n",
      "     Economic       0.87      0.77      0.82        44\n",
      "       Health       1.00      0.70      0.82        23\n",
      "    Political       0.83      0.91      0.87        70\n",
      "       Sports       0.98      1.00      0.99        53\n",
      "    Terrorism       0.81      0.87      0.84        30\n",
      "\n",
      "  avg / total       0.91      0.91      0.91       425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Crime', 'Disaster', 'Entertainment', 'Economic','Health','Political','Sports','Terrorism']\n",
    "print(classification_report(y_testArray, pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save to pickle\n",
    "import pickle\n",
    "\n",
    "with open('categorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "    \n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REALLY NEW DATA OMGGGGG!!\n",
    "#UAAP: Ateneo pilay kontra FEU By Elech Dawa March 9 na news ni siya\n",
    "arr = \"target ateneo first round sweep harap far eastern university ngayon araw uaap season mens football tournament moro lorenzo field sikap blue eag­les  dagit sweep wala league-leading goalscorer jarvey gayoso nabigyan si sopho­more striker gayoso five goals season dalawa yellow cards suspendido laro kontra tamaraws kaldag una laro ust nu salo fourth place points kritikal laro dalawa habol sa final four bayani gayoso rookies sam lim enzo ceniza may maximum points ateneo lima puntos una segundong up feu tigatlong goals isasalpak ngayong season lim at ceniza nais tamaraws balik tikas depensa laban blue eagles\"\n",
    "testing = vectorizer.transform([arr])\n",
    "clf.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter:Suicide bombing sa Cebu kahapon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = raw_input(\"Enter:\")\n",
    "a = remove_punct_num.removePunctuationAndNumbers(a)\n",
    "a = remove_stopwords.remove_stopwords(a)\n",
    "a = stemmer2.stem(a)\n",
    "testing = vectorizer.transform([a])\n",
    "clf.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
