{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocessing import remove_punct_num\n",
    "from preprocessing import remove_stopwords\n",
    "from preprocessing import stemmer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/no_stemming.csv')\n",
    "X, y = df['content'], df['multiclass']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42)\n",
    "# random_state = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/experiment1/shuffled.csv')\n",
    "X, y = df['content'], df['multiclass']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42)\n",
    "# random_state = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1696, 22824)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1) #  max_features=100, binary=True, norm=None, use_idf=False\n",
    "X= vectorizer.fit_transform(X_train) \n",
    "train_data_features = X.toarray()\n",
    "\n",
    "print train_data_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1696, 22824)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1, binary=True, norm=None, use_idf=False) #max_features=30000\n",
    "X= vectorizer.fit_transform(X_train) \n",
    "train_data_features = X.toarray()\n",
    "\n",
    "print train_data_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1696, 22824)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=1, max_features=30000) #, binary=True, norm=None, use_idf=False\n",
    "X= vectorizer.fit_transform(X_train) \n",
    "train_data_features = X.toarray()\n",
    "\n",
    "print train_data_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC(C=1.0,random_state=42, max_iter=1000)) # C=1.0\n",
    "clf.fit(train_data_features,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(train_data_features,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915294117647\n"
     ]
    }
   ],
   "source": [
    "test_data_features = vectorizer.transform(X_test)\n",
    "pred = clf.predict(test_data_features)\n",
    "accuracy = clf.score(test_data_features,y_test)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.74142628  0.71725786  0.75198413  0.68480998  0.7324627   0.81816239\n",
      "  0.64583333  0.76722756  0.75999246  0.60307854]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, test_data_features, y_test, cv=10, scoring='f1_macro')\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print pred\n",
    "# print pred.shape\n",
    "# print y_test.values\n",
    "\n",
    "X_testArray = X_test.values\n",
    "y_testArray = y_test.values\n",
    "\n",
    "# for i in range(len(X_test)):\n",
    "#     print X_testArray[i] \n",
    "#     print \"label: \", y_testArray[i] \n",
    "#     print \"predicted: \", pred[i]\n",
    "#     print \"\\n\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0=crime 1=disaster 2=entertainment 3=economic 4=health 5=political 6=sports 7=terrorism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60  1  0  1  0  2  0  0]\n",
      " [ 2 63  0  0  0  1  0  0]\n",
      " [ 0  0 72  0  0  0  0  0]\n",
      " [ 0  4  0 33  0 11  0  0]\n",
      " [ 0  2  0  0 19  2  0  1]\n",
      " [ 2  1  0  1  0 66  0  1]\n",
      " [ 0  0  1  0  0  0 63  0]\n",
      " [ 1  0  0  0  0  2  0 13]]\n"
     ]
    }
   ],
   "source": [
    "# row : actual :: column : predicted \n",
    "cf = confusion_matrix(y_testArray,pred)\n",
    "print cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime\n",
      "60 4 5 356\n",
      "Precision:  0.923076923077\n",
      "Recall:  0.9375\n",
      " \n",
      "Disaster\n",
      "63 3 8 351\n",
      "Precision:  0.887323943662\n",
      "Recall:  0.954545454545\n",
      " \n",
      "Entertainment\n",
      "72 0 1 352\n",
      "Precision:  0.986301369863\n",
      "Recall:  1.0\n",
      " \n",
      "Economic\n",
      "33 15 2 375\n",
      "Precision:  0.942857142857\n",
      "Recall:  0.6875\n",
      " \n",
      "Health\n",
      "19 5 0 401\n",
      "Precision:  1.0\n",
      "Recall:  0.791666666667\n",
      " \n",
      "Political\n",
      "66 5 18 336\n",
      "Precision:  0.785714285714\n",
      "Recall:  0.929577464789\n",
      " \n",
      "Sports\n",
      "63 1 0 361\n",
      "Precision:  1.0\n",
      "Recall:  0.984375\n",
      " \n",
      "Terrorism\n",
      "13 3 2 407\n",
      "Precision:  0.866666666667\n",
      "Recall:  0.8125\n",
      " \n",
      "hey  389 36 36 2939\n"
     ]
    }
   ],
   "source": [
    "# 8 total classes\n",
    "from __future__ import division\n",
    "\n",
    "total = 8\n",
    "classes = {0:'Crime', 1:'Disaster', 2:'Entertainment', 3:'Economic', 4:'Health', 5:'Political',\n",
    "          6:'Sports', 7:'Terrorism'}\n",
    "category = 0\n",
    "\n",
    "TrueP = []\n",
    "FalseN = []\n",
    "FalseP = []\n",
    "TrueN = []\n",
    "\n",
    "\n",
    "for category in range(total):\n",
    "    TP = FN = FP = TN = 0 \n",
    "    for i in range(total):\n",
    "        for j in range(total):\n",
    "            if i==category and j==category:\n",
    "                TP += cf[i][j]\n",
    "            elif i==category and j!=category:\n",
    "                FN += cf[i][j]\n",
    "            elif i!=category and j==category:\n",
    "                FP += cf[i][j]\n",
    "            else:\n",
    "                TN += cf[i][j]\n",
    "    print classes.get(category)\n",
    "    print TP, FN, FP, TN\n",
    "    print \"Precision: \" , TP/(TP+FP)\n",
    "    print \"Recall: \" , TP/(TP+FN)\n",
    "    print \" \"\n",
    "    TrueP.append(TP)\n",
    "    FalseN.append(FN)\n",
    "    FalseP.append(FP)\n",
    "    TrueN.append(TN)\n",
    "    \n",
    "# Average confusion matrix for all classes\n",
    "TP = np.sum(TrueP)\n",
    "FN = np.sum(FalseN)\n",
    "FP = np.sum(FalseP)\n",
    "TN = np.sum(TrueN)  \n",
    "\n",
    "print  \"hey \",  TP, FN, FP, TN\n",
    "\n",
    "# PPV = TP / (TP + FP) \n",
    "# TPR = TP / (TP + FN)\n",
    "# Fscore = 2 * ((PPV * TPR)/(PPV + TPR))\n",
    "\n",
    "# print \" \"\n",
    "# print \"Precision: \" , PPV\n",
    "# print \"Recall: \" , TPR\n",
    "# print \"F-score: \" , Fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93023256  0.91970803  0.99310345  0.79518072  0.88372093  0.8516129\n",
      "  0.99212598  0.83870968]\n",
      "\n",
      "\n",
      "0.900549281704\n"
     ]
    }
   ],
   "source": [
    "# calculate f-score for each category\n",
    "f1 = f1_score(y_testArray,pred, average=None)\n",
    "\n",
    "print f1\n",
    "print \"\\n\"\n",
    "print np.sum(f1)/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score\n",
      "-----\n",
      "Weighted:  0.91411052449\n",
      "Micro:  0.915294117647\n",
      "Macro:  0.900549281704\n"
     ]
    }
   ],
   "source": [
    "# calculate f-score for all \n",
    "print \"F-score\\n-----\"\n",
    "print \"Weighted: \", f1_score(y_testArray,pred, average='weighted')\n",
    "print \"Micro: \", f1_score(y_testArray,pred, average='micro')\n",
    "print \"Macro: \", f1_score(y_testArray,pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save to pickle\n",
    "import pickle\n",
    "\n",
    "with open('categorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "    \n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REALLY NEW DATA OMGGGGG!!\n",
    "#UAAP: Ateneo pilay kontra FEU By Elech Dawa March 9 na news ni siya\n",
    "arr = \"target ateneo first round sweep harap far eastern university ngayon araw uaap season mens football tournament moro lorenzo field sikap blue eag­les  dagit sweep wala league-leading goalscorer jarvey gayoso nabigyan si sopho­more striker gayoso five goals season dalawa yellow cards suspendido laro kontra tamaraws kaldag una laro ust nu salo fourth place points kritikal laro dalawa habol sa final four bayani gayoso rookies sam lim enzo ceniza may maximum points ateneo lima puntos una segundong up feu tigatlong goals isasalpak ngayong season lim at ceniza nais tamaraws balik tikas depensa laban blue eagles\"\n",
    "testing = vectorizer.transform([arr])\n",
    "clf.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = raw_input(\"Enter:\")\n",
    "a = remove_punct_num.removePunctuationAndNumbers(a)\n",
    "a = remove_stopwords.remove_stopwords(a)\n",
    "a = stemmer2.stem(a)\n",
    "testing = vectorizer.transform([a])\n",
    "clf.predict(testing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
