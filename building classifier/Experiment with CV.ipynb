{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from preprocessing import remove_punct_num\n",
    "from preprocessing import remove_stopwords\n",
    "from preprocessing import stemmer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(*args):\n",
    "    X_train, X_test = args[2][args[0]], args[2][args[1]]\n",
    "    y_train, y_test = args[3][args[0]], args[3][args[1]]\n",
    "    \n",
    "    # count\n",
    "    training = [0,0,0,0,0,0,0,0]\n",
    "    testing = [0,0,0,0,0,0,0,0]\n",
    "\n",
    "    for y in y_train:\n",
    "        training[y] += 1\n",
    "\n",
    "    for y in y_test:\n",
    "        testing[y] += 1\n",
    "\n",
    "    print \"Training Set:\" , training\n",
    "    print \"Testing Set:\" , testing\n",
    "    #     \n",
    "    \n",
    "     # tf-idf vectorizer \n",
    "    if (int(args[4]) == 1):\n",
    "        vec =  binary(X_train)\n",
    "        vectorizer = vec[0]\n",
    "        train_data_features = vec[1]\n",
    "    elif (int(args[4]) == 2):\n",
    "        vec = word_count(X_train)\n",
    "        vectorizer = vec[0]\n",
    "        train_data_features = vec[1]\n",
    "    else:\n",
    "        vec = tf_idf(X_train)\n",
    "        vectorizer = vec[0]\n",
    "        train_data_features = vec[1]\n",
    "    \n",
    "    # svm\n",
    "    if int(args[5]) == 1:\n",
    "        clf = run_svm(train_data_features,y_train)\n",
    "    else:\n",
    "        clf = run_mnb(train_data_features,y_train_)\n",
    "\n",
    "    #\n",
    "    X_testArray = X_test.values\n",
    "    y_testArray = y_test.values\n",
    "    \n",
    "    #accuracy\n",
    "    test_data_features = vectorizer.transform(X_test)\n",
    "    pred = clf.predict(test_data_features)\n",
    "    accuracy = clf.score(test_data_features,y_test)\n",
    "    print \"accuracy:\", accuracy\n",
    "    \n",
    "    f1 = f1_score(y_testArray,pred, average=None)\n",
    "    avg = np.sum(f1)/8\n",
    "    print \"f-score: \", f1\n",
    "    print \"avg:\", avg\n",
    "    \n",
    "    print \"\\n\\n\"\n",
    "    return (clf, vectorizer, f1, avg, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tf_idf(*args):\n",
    "    vectorizer = TfidfVectorizer(min_df=1) # max_features=10000, binary=True, norm=None, use_idf=False\n",
    "    X= vectorizer.fit_transform(args[0]) \n",
    "    train_data_features = X.toarray()\n",
    "\n",
    "    print train_data_features.shape\n",
    "    return (vectorizer,train_data_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def binary(*args):\n",
    "    vectorizer = TfidfVectorizer(min_df=1, binary=True, norm=None, use_idf=False) #max_features=30000\n",
    "    X= vectorizer.fit_transform(args[0]) \n",
    "    train_data_features = X.toarray()\n",
    "\n",
    "    print train_data_features.shape\n",
    "    return (vectorizer,train_data_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word_count(*args):\n",
    "    vectorizer = CountVectorizer(min_df=1, max_features=30000) #, binary=True, norm=None, use_idf=False\n",
    "    X= vectorizer.fit_transform(args[0]) \n",
    "    train_data_features = X.toarray()\n",
    "\n",
    "    print train_data_features.shape\n",
    "    return (vectorizer,train_data_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_svm(*args):\n",
    "    clf = OneVsRestClassifier(LinearSVC(C=1.0,random_state=42)) # C=1.0, max_iter=1000\n",
    "    clf.fit(args[0],args[1])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_mnb(*args):    \n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(args[0],args[1])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction\n",
      "1.Binary\n",
      "2.Word Count\n",
      "3.TF-IDF\n",
      "Choose: 3\n",
      "Classifier\n",
      "1.SVM\n",
      "2.Multinomial Naive Bayes\n",
      "Choose: 1\n",
      "\n",
      "\n",
      "Iteration:  0\n",
      "Training Set: [214, 249, 245, 176, 81, 254, 201, 105]\n",
      "Testing Set: [22, 27, 20, 14, 8, 42, 25, 12]\n",
      "(1525, 22076)\n",
      "accuracy: 0.894117647059\n",
      "f-score:  [ 0.80851064  0.92592593  0.97560976  0.78571429  0.66666667  0.9047619\n",
      "  0.96        0.91666667]\n",
      "avg: 0.867981980516\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  1\n",
      "Training Set: [218, 243, 243, 168, 78, 271, 198, 106]\n",
      "Testing Set: [18, 33, 22, 22, 11, 25, 28, 11]\n",
      "(1525, 21869)\n",
      "accuracy: 0.935294117647\n",
      "f-score:  [ 0.94444444  0.95652174  0.97777778  0.84210526  0.9         0.87272727\n",
      "  1.          0.95238095]\n",
      "avg: 0.930744681202\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  2\n",
      "Training Set: [210, 247, 241, 171, 76, 266, 204, 110]\n",
      "Testing Set: [26, 29, 24, 19, 13, 30, 22, 7]\n",
      "(1525, 21913)\n",
      "accuracy: 0.882352941176\n",
      "f-score:  [ 0.92307692  0.8852459   1.          0.66666667  0.83333333  0.8125      1.\n",
      "  0.85714286]\n",
      "avg: 0.872245710232\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  3\n",
      "Training Set: [212, 245, 234, 175, 76, 278, 205, 100]\n",
      "Testing Set: [24, 31, 31, 15, 13, 18, 21, 17]\n",
      "(1525, 21974)\n",
      "accuracy: 0.917647058824\n",
      "f-score:  [ 0.89361702  0.95081967  1.          0.8         0.83333333  0.85        1.\n",
      "  0.88235294]\n",
      "avg: 0.90126537099\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  4\n",
      "Training Set: [216, 252, 238, 163, 81, 262, 206, 107]\n",
      "Testing Set: [20, 24, 27, 27, 8, 34, 20, 10]\n",
      "(1525, 22047)\n",
      "accuracy: 0.905882352941\n",
      "f-score:  [ 0.88888889  0.89795918  0.98113208  0.82352941  0.875       0.90140845\n",
      "  0.97560976  0.86956522]\n",
      "avg: 0.901636622999\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  5\n",
      "Training Set: [212, 248, 240, 171, 79, 268, 199, 109]\n",
      "Testing Set: [24, 28, 25, 19, 10, 28, 27, 8]\n",
      "(1526, 21887)\n",
      "accuracy: 0.91124260355\n",
      "f-score:  [ 0.86956522  0.89655172  0.97959184  0.89473684  0.9         0.82142857\n",
      "  1.          0.94117647]\n",
      "avg: 0.912881332798\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  6\n",
      "Training Set: [206, 254, 239, 165, 84, 269, 206, 103]\n",
      "Testing Set: [30, 22, 26, 25, 5, 27, 20, 14]\n",
      "(1526, 21955)\n",
      "accuracy: 0.923076923077\n",
      "f-score:  [ 0.88135593  0.86956522  1.          0.95833333  0.90909091  0.92592593\n",
      "  0.97560976  0.81481481]\n",
      "avg: 0.916836986107\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  7\n",
      "Training Set: [212, 247, 228, 174, 81, 272, 203, 109]\n",
      "Testing Set: [24, 29, 37, 16, 8, 24, 23, 8]\n",
      "(1526, 21886)\n",
      "accuracy: 0.92899408284\n",
      "f-score:  [ 0.88461538  0.89285714  1.          0.90322581  1.          0.875\n",
      "  0.9787234   0.85714286]\n",
      "avg: 0.923945574415\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  8\n",
      "Training Set: [214, 257, 240, 169, 81, 262, 203, 100]\n",
      "Testing Set: [22, 19, 25, 21, 8, 34, 23, 17]\n",
      "(1526, 22061)\n",
      "accuracy: 0.94674556213\n",
      "f-score:  [ 0.90909091  0.97435897  0.98039216  0.97560976  1.          0.91176471\n",
      "  0.97777778  0.88235294]\n",
      "avg: 0.951418402656\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  9\n",
      "Training Set: [210, 242, 237, 178, 84, 262, 209, 104]\n",
      "Testing Set: [26, 34, 28, 12, 5, 34, 17, 13]\n",
      "(1526, 21824)\n",
      "accuracy: 0.92899408284\n",
      "f-score:  [ 0.90566038  0.98550725  1.          0.72727273  0.90909091  0.86956522\n",
      "  1.          0.91666667]\n",
      "avg: 0.91422039302\n",
      "\n",
      "\n",
      "\n",
      "OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0),\n",
      "          n_jobs=1) [ 0.90909091  0.97435897  0.98039216  0.97560976  1.          0.91176471\n",
      "  0.97777778  0.88235294] 0.951418402656\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#df = pd.read_csv('../data/experiment1/shuffled_updated.csv')\n",
    "#df = pd.read_csv('../data/no_stemming.csv')\n",
    "df = pd.read_csv('../data/experiment1/shuffled1.csv')\n",
    "\n",
    "X, y = df['content'][:1695], df['multiclass'][:1695]\n",
    "\n",
    "clf_est = []\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "feat = raw_input(\"Feature Extraction\\n1.Binary\\n2.Word Count\\n3.TF-IDF\\nChoose: \")\n",
    "c = raw_input(\"Classifier\\n1.SVM\\n2.Multinomial Naive Bayes\\nChoose: \")\n",
    "print \"\\n\"\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print \"Iteration: \", i\n",
    "    clf_est.append(evaluate(train_index,test_index, X, y, feat, c))\n",
    "    i += 1\n",
    "    \n",
    "best_estimator = max(clf_est,key=itemgetter(3))\n",
    "print best_estimator[0], best_estimator[2], best_estimator[3]\n",
    "\n",
    "clf = best_estimator[0]\n",
    "vectorizer = best_estimator[1]\n",
    "\n",
    "X_test, y_test = df['content'][1696:], df['multiclass'][1696:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908235294118\n"
     ]
    }
   ],
   "source": [
    "test_data_features = vectorizer.transform(X_test)\n",
    "pred = clf.predict(test_data_features)\n",
    "accuracy = clf.score(test_data_features,y_test)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0=crime 1=disaster 2=entertainment 3=economic 4=health 5=political 6=sports 7=terrorism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print pred\n",
    "# print pred.shape\n",
    "# print y_test.values\n",
    "\n",
    "X_testArray = X_test.values\n",
    "y_testArray = y_test.values\n",
    "\n",
    "# for i in range(len(X_test)):\n",
    "#     print X_testArray[i] \n",
    "#     print \"label: \", y_testArray[i] \n",
    "#     print \"predicted: \", pred[i]\n",
    "#     print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53  2  0  1  0  1  0  2]\n",
      " [ 4 63  0  1  0  3  0  0]\n",
      " [ 0  1 63  0  0  0  0  0]\n",
      " [ 0  1  0 39  0  4  0  0]\n",
      " [ 1  3  1  1 10  0  0  1]\n",
      " [ 0  0  0  4  0 64  0  0]\n",
      " [ 0  0  1  0  0  0 72  0]\n",
      " [ 2  1  0  0  0  4  0 22]]\n"
     ]
    }
   ],
   "source": [
    "# row : actual :: column : predicted \n",
    "cf = confusion_matrix(y_testArray,pred)\n",
    "print cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime\n",
      "53 6 7 359\n",
      "Precision:  0.883333333333\n",
      "Recall:  0.898305084746\n",
      " \n",
      "Disaster\n",
      "63 8 8 346\n",
      "Precision:  0.887323943662\n",
      "Recall:  0.887323943662\n",
      " \n",
      "Entertainment\n",
      "63 1 2 359\n",
      "Precision:  0.969230769231\n",
      "Recall:  0.984375\n",
      " \n",
      "Economic\n",
      "39 5 7 374\n",
      "Precision:  0.847826086957\n",
      "Recall:  0.886363636364\n",
      " \n",
      "Health\n",
      "10 7 0 408\n",
      "Precision:  1.0\n",
      "Recall:  0.588235294118\n",
      " \n",
      "Political\n",
      "64 4 12 345\n",
      "Precision:  0.842105263158\n",
      "Recall:  0.941176470588\n",
      " \n",
      "Sports\n",
      "72 1 0 352\n",
      "Precision:  1.0\n",
      "Recall:  0.986301369863\n",
      " \n",
      "Terrorism\n",
      "22 7 3 393\n",
      "Precision:  0.88\n",
      "Recall:  0.758620689655\n",
      " \n",
      "pre:  0.913727424543\n",
      "rec: 0.866337686124\n",
      "hey  386 39 39 2936 0.977058823529\n"
     ]
    }
   ],
   "source": [
    "# 8 total classes\n",
    "from __future__ import division\n",
    "\n",
    "total = 8\n",
    "classes = {0:'Crime', 1:'Disaster', 2:'Entertainment', 3:'Economic', 4:'Health', 5:'Political',\n",
    "          6:'Sports', 7:'Terrorism'}\n",
    "category = 0\n",
    "\n",
    "TrueP = []\n",
    "FalseN = []\n",
    "FalseP = []\n",
    "TrueN = []\n",
    "\n",
    "pre = 0\n",
    "rec = 0\n",
    "\n",
    "for category in range(total):\n",
    "    TP = FN = FP = TN = 0 \n",
    "    for i in range(total):\n",
    "        for j in range(total):\n",
    "            if i==category and j==category:\n",
    "                TP += cf[i][j]\n",
    "            elif i==category and j!=category:\n",
    "                FN += cf[i][j]\n",
    "            elif i!=category and j==category:\n",
    "                FP += cf[i][j]\n",
    "            else:\n",
    "                TN += cf[i][j]\n",
    "    print classes.get(category)\n",
    "    print TP, FN, FP, TN\n",
    "    print \"Precision: \" , TP/(TP+FP)\n",
    "    print \"Recall: \" , TP/(TP+FN)\n",
    "    print \" \"\n",
    "    TrueP.append(TP)\n",
    "    FalseN.append(FN)\n",
    "    FalseP.append(FP)\n",
    "    TrueN.append(TN)\n",
    "    pre += (TP/(TP+FP))\n",
    "    rec += TP/(TP+FN)\n",
    "\n",
    "print \"pre: \", pre/8\n",
    "print \"rec:\", rec/8\n",
    "    \n",
    "# Average confusion matrix for all classes\n",
    "TP = np.sum(TrueP)\n",
    "FN = np.sum(FalseN)\n",
    "FP = np.sum(FalseP)\n",
    "TN = np.sum(TrueN)  \n",
    "\n",
    "print  \"hey \",  TP, FN, FP, TN, ((TP+TN)/(TP+TN+FP+FN))\n",
    "\n",
    "# PPV = TP / (TP + FP) \n",
    "# TPR = TP / (TP + FN)\n",
    "# Fscore = 2 * ((PPV * TPR)/(PPV + TPR))\n",
    "\n",
    "# print \" \"\n",
    "# print \"Precision: \" , PPV\n",
    "# print \"Recall: \" , TPR\n",
    "# print \"F-score: \" , Fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8907563   0.88732394  0.97674419  0.86666667  0.74074074  0.88888889\n",
      "  0.99310345  0.81481481]\n",
      "\n",
      "\n",
      "0.882379873952\n"
     ]
    }
   ],
   "source": [
    "# calculate f-score for each category\n",
    "f1 = f1_score(y_testArray,pred, average=None)\n",
    "\n",
    "print f1\n",
    "print \"\\n\"\n",
    "print np.sum(f1)/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score\n",
      "-----\n",
      "Weighted:  0.906736003482\n",
      "Micro:  0.908235294118\n",
      "Macro:  0.882379873952\n"
     ]
    }
   ],
   "source": [
    "# calculate f-score for all \n",
    "print \"F-score\\n-----\"\n",
    "print \"Weighted: \", f1_score(y_testArray,pred, average='weighted')\n",
    "print \"Micro: \", f1_score(y_testArray,pred, average='micro')\n",
    "print \"Macro: \", f1_score(y_testArray,pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Crime       0.88      0.90      0.89        59\n",
      "     Disaster       0.89      0.89      0.89        71\n",
      "Entertainment       0.97      0.98      0.98        64\n",
      "     Economic       0.85      0.89      0.87        44\n",
      "       Health       1.00      0.59      0.74        17\n",
      "    Political       0.84      0.94      0.89        68\n",
      "       Sports       1.00      0.99      0.99        73\n",
      "    Terrorism       0.88      0.76      0.81        29\n",
      "\n",
      "  avg / total       0.91      0.91      0.91       425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Crime', 'Disaster', 'Entertainment', 'Economic','Health','Political','Sports','Terrorism']\n",
    "print(classification_report(y_testArray, pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save to pickle\n",
    "import pickle\n",
    "\n",
    "with open('categorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "    \n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REALLY NEW DATA OMGGGGG!!\n",
    "#UAAP: Ateneo pilay kontra FEU By Elech Dawa March 9 na news ni siya\n",
    "arr = \"target ateneo first round sweep harap far eastern university ngayon araw uaap season mens football tournament moro lorenzo field sikap blue eag­les  dagit sweep wala league-leading goalscorer jarvey gayoso nabigyan si sopho­more striker gayoso five goals season dalawa yellow cards suspendido laro kontra tamaraws kaldag una laro ust nu salo fourth place points kritikal laro dalawa habol sa final four bayani gayoso rookies sam lim enzo ceniza may maximum points ateneo lima puntos una segundong up feu tigatlong goals isasalpak ngayong season lim at ceniza nais tamaraws balik tikas depensa laban blue eagles\"\n",
    "testing = vectorizer.transform([arr])\n",
    "clf.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter:Suicide bombing sa Cebu kahapon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = raw_input(\"Enter:\")\n",
    "a = remove_punct_num.removePunctuationAndNumbers(a)\n",
    "a = remove_stopwords.remove_stopwords(a)\n",
    "a = stemmer2.stem(a)\n",
    "testing = vectorizer.transform([a])\n",
    "clf.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
